# verity

A sovereign, hardened Alpine Linux ISO that boots directly into nginx. No shell, no package manager, no SSH — just your services on a read-only root filesystem.

## What is sovereignty?

Most servers are held together by trust in things you don't control — upstream repos, package managers, update daemons, shell access that "probably nobody will use." Every one of those is an assumption, and every assumption is a surface.

Sovereignty means your server runs exactly what you built, nothing more. Verity achieves this by eliminating every component that isn't strictly necessary:

- **No package manager.** apk, alpine's package manager, is deleted after build. Nothing can be installed at runtime.
- **No shell.** There is no way to get an interactive session. No SSH, no TTY, no login.
- **No mutation.** The root filesystem is squashfs — read-only by nature, not by policy. There is no `remount,rw`.
- **No ambient authority.** Kernel module loading is disabled after boot. ptrace is restricted. kexec is off.
- **No opinions you didn't choose.** The entire system is a handful of auditable files. You can read all of it in one sitting.

The result is a machine that does exactly what you configured, can't be told to do anything else, and can be fully understood by one person.

## Quick start

```
make configure   # choose which components to include
make build       # builds the ISO (uses Docker on macOS)
make test        # boots in QEMU with port 8080 forwarded
curl http://localhost:8080
```

## Components

Verity has an interactive configure step that lets you choose what to include:

| Component | Default | Description |
|-----------|---------|-------------|
| **nginx** | Always | Static file server / reverse proxy (PID 1) |
| **mDNS (avahi)** | Off | Advertises `verity.local` on the network |
| **Node.js** | Off | API server on `127.0.0.1:3000`, proxied via nginx at `/api/` |
| **PostgreSQL** | Off | Ephemeral database (requires Node.js) — data lives on tmpfs, lost on every reboot |

Run `make configure` to select components. This writes a `verity.conf` file that the build script sources. Without a config, only nginx is included (same as before).

### Ephemeral database

PostgreSQL data lives at `/tmp/pgdata` on a tmpfs mount. Every reboot starts fresh — `initdb`, `createdb`, and `seed.sql` run on every boot. This is by design: the appliance is stateless and auditable. If you need persistence, back up via the API.

## What it does

Verity builds a bootable ISO that:

- Boots via ISOLINUX into a custom initramfs
- Mounts a squashfs root filesystem (read-only)
- Brings up networking via DHCP
- Applies kernel hardening (sysctl)
- Starts configured services in dependency order
- Runs nginx as PID 1 — if it dies, kernel panic

## Boot chain

```
BIOS → ISOLINUX → vmlinuz + initramfs
  → initramfs-init loads modules (squashfs, loop, isofs, sr_mod, virtio)
  → scans block devices for rootfs.squashfs
  → mounts squashfs read-only → switch_root
  → /sbin/init (generated by build.sh):
      1. mount proc/sys/dev + tmpfs
      2. remount / read-only
      3. networking (lo, eth0, DHCP)
      4. sysctl hardening
      5. avahi-daemon        (if configured)
      6. initdb + pg_ctl     (if configured)
      7. node server.js      (if configured)
      8. exec nginx          (always — becomes PID 1)
```

## Project layout

```
scripts/
  configure.sh    # interactive component selector → writes verity.conf
  build.sh        # main build script (run as root or via Docker)
  initramfs-init  # initramfs /init — finds and mounts the squashfs
  test.sh         # QEMU test helper
config/
  init            # reference PID 1 init (nginx-only)
  nginx.conf      # nginx config for static-only mode
  nginx-proxy.conf # nginx config with Node.js reverse proxy
  avahi-daemon.conf # mDNS configuration
  sysctl.conf     # kernel hardening parameters
app/
  server.js       # Node.js API server (health + info endpoints)
  package.json    # Node.js dependencies
  seed.sql        # bootstrap SQL (runs on every boot)
www/
  index.html      # default landing page
Makefile          # build orchestration
```

## API endpoints (when Node.js is enabled)

- `GET /api/health` — `{ "status": "ok", "time": "..." }` (includes DB timestamp if PostgreSQL enabled)
- `GET /api/info` — `{ "name": "verity", "node": "v...", "uptime": ..., "db": "connected" }`

## Build requirements

**Linux (native):** `bash`, `wget`, `xorriso`, `squashfs-tools`, `cpio`, `syslinux`, root access

**macOS:** Docker (the Makefile runs the build inside `alpine:3.21`)

**Testing:** `qemu-system-x86_64`

## Customization

Replace `www/index.html` (or add files to `www/`) with your static site content. Edit `config/nginx.conf` or `config/nginx-proxy.conf` to adjust the server configuration. Add API routes in `app/server.js`.

## Security

- Read-only squashfs root
- No shell access, no package manager, no SSH
- Kernel hardening via sysctl (ASLR, kptr_restrict, module loading disabled post-boot)
- nginx security headers: CSP, X-Frame-Options DENY, X-Content-Type-Options, Permissions-Policy
- Rate limiting (10 req/s per IP)
- Server version hidden
- npm removed at runtime (node binary kept)
- PostgreSQL trusts localhost only — no shell exists to abuse it
- Node.js binds `127.0.0.1` only — accessible via nginx reverse proxy

## License

MIT
